"""
Indicators Calculator Module for Exploratory Analysis

This module contains classes and functions for calculating key indicators
during exploratory data analysis of real estate data.

Author: Juan Camilo Ria√±o Molano
Date: 08/08/2025
"""

import pandas as pd
import numpy as np


class KeyIndicatorsCalculator:
    """
    Clase responsable del c√°lculo de indicadores clave de negocio
    """
    
    def __init__(self):
        """Inicializar la calculadora de indicadores"""
        self.indicators = {}
        self.statistics = {}
    
    def calculate_price_per_m2(self, df_muestra):
        """
        Calcular precio promedio por metro cuadrado
        """
        try:
            # Convertir a num√©rico
            df_temp = df_muestra.copy()
            df_temp["Precio_Solicitado"] = pd.to_numeric(df_temp["Precio_Solicitado"], errors='coerce')
            df_temp["Area"] = pd.to_numeric(df_temp["Area"], errors='coerce')
            
            # Filtrar datos v√°lidos
            df_temp = df_temp.dropna(subset=["Precio_Solicitado", "Area"])
            df_temp = df_temp[df_temp["Area"] > 0]  # Evitar divisi√≥n por cero
            
            # Calcular precio por m¬≤
            df_temp["Precio_por_m2"] = df_temp["Precio_Solicitado"] / df_temp["Area"]
            
            # Filtrar outliers extremos usando IQR
            Q1 = df_temp["Precio_por_m2"].quantile(0.25)
            Q3 = df_temp["Precio_por_m2"].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            df_filtered = df_temp[
                (df_temp["Precio_por_m2"] >= lower_bound) & 
                (df_temp["Precio_por_m2"] <= upper_bound)
            ]
            
            promedio_precio_m2 = df_filtered["Precio_por_m2"].mean()
            
            return promedio_precio_m2
            
        except Exception as e:
            print(f"Error calculando precio por m¬≤: {e}")
            return 0
    
    def calcular_indicadores_clave(self, df_muestra, df_estados=None, data_stage="procesados"):
        """
        Calcular todos los indicadores clave del proyecto
        """
        try:
            print("\n" + "=" * 60)
            print("          INDICADORES CLAVE DEL PROYECTO")
            print("=" * 60)
            
            # Agregar aclaraci√≥n de etapa de datos
            stage_emoji = "üìä" if data_stage == "procesados" else "‚ú®"
            stage_description = "DATOS ORIGINALES (antes de limpieza)" if data_stage == "procesados" else "DATOS LIMPIOS (despu√©s de procesamiento)"
            print(f"{stage_emoji} AN√ÅLISIS DE: {stage_description}")
            print("=" * 60)
            
            # 1. Precio promedio por m¬≤
            precio_promedio_m2 = self.calculate_price_per_m2(df_muestra)
            print(f"‚Ä¢ Precio promedio por m¬≤: ${precio_promedio_m2:,.0f} COP/m¬≤")
            
            # 2. Tasa de confiabilidad (porcentaje de completitud)
            total_registros = len(df_muestra)
            columnas_criticas = ["Precio_Solicitado", "Area", "Ciudad", "Zona", "Tipo_Inmueble"]
            registros_completos = df_muestra.dropna(subset=columnas_criticas)
            tasa_confiabilidad = (len(registros_completos) / total_registros) * 100
            print(f"‚Ä¢ Tasa de confiabilidad: {tasa_confiabilidad:.1f}% ({len(registros_completos):,} registros completos de {total_registros:,})")
            
            # 3. Outliers identificados
            try:
                df_temp = df_muestra.copy()
                df_temp["Precio_Solicitado"] = pd.to_numeric(df_temp["Precio_Solicitado"], errors='coerce')
                df_temp = df_temp.dropna(subset=["Precio_Solicitado"])
                
                # Usar IQR para detectar outliers
                Q1 = df_temp["Precio_Solicitado"].quantile(0.25)
                Q3 = df_temp["Precio_Solicitado"].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = df_temp[
                    (df_temp["Precio_Solicitado"] < lower_bound) | 
                    (df_temp["Precio_Solicitado"] > upper_bound)
                ]
                
                num_outliers = len(outliers)
                total_analizados = len(df_temp)
                min_precio = outliers["Precio_Solicitado"].min() if num_outliers > 0 else 0
                max_precio = outliers["Precio_Solicitado"].max() if num_outliers > 0 else 0
                
                print(f"‚Ä¢ Outliers identificados: {num_outliers} de {total_analizados:,} registros (rangos: ${min_precio:,.0f} ‚Äì ${max_precio:,.0f} COP)")
                
            except Exception as e:
                print(f"‚Ä¢ Outliers identificados: Error en c√°lculo ({e})")
            
            # 4. An√°lisis de estados (si est√° disponible)
            if df_estados is not None:
                try:
                    # Calcular tiempo promedio en "Revisar Direcci√≥n"
                    revisar_direccion = df_estados[df_estados["Estado"].str.contains("Revisar Direcci√≥n", case=False, na=False)]
                    num_revisar = len(revisar_direccion)
                    
                    # Calcular tiempo promedio si hay datos
                    tiempo_promedio = 0.0
                    if num_revisar > 0:
                        # Calcular tiempo en cada estado
                        for inmueble_id in revisar_direccion["Inmueble_ID"].unique():
                            estados_inmueble = df_estados[df_estados["Inmueble_ID"] == inmueble_id].sort_values("Fecha_Actualizacion")
                            
                            for idx, row in estados_inmueble.iterrows():
                                if "Revisar Direcci√≥n" in str(row["Estado"]):
                                    # Buscar siguiente estado
                                    siguiente_idx = estados_inmueble.index.get_loc(idx) + 1
                                    if siguiente_idx < len(estados_inmueble):
                                        siguiente_estado = estados_inmueble.iloc[siguiente_idx]
                                        tiempo_diff = pd.to_datetime(siguiente_estado["Fecha_Actualizacion"]) - pd.to_datetime(row["Fecha_Actualizacion"])
                                        tiempo_promedio += tiempo_diff.days
                                        break
                        
                        tiempo_promedio = tiempo_promedio / num_revisar if num_revisar > 0 else 0
                    
                    print(f"‚Ä¢ Leads en 'Revisar Direcci√≥n': {num_revisar} (tiempo promedio: {tiempo_promedio:.1f} d√≠as)")
                    
                except Exception as e:
                    print(f"‚Ä¢ Leads en 'Revisar Direcci√≥n': Error en c√°lculo ({e})")
            
            # 5. Porcentaje descartados
            try:
                estados_descartados = ["Descartado", "Rechazado", "No Viable"]
                if df_estados is not None:
                    total_inmuebles = df_estados["Inmueble_ID"].nunique()
                    descartados = 0
                    for estado in estados_descartados:
                        descartados += len(df_estados[df_estados["Estado"].str.contains(estado, case=False, na=False)])
                    
                    porcentaje_descartados = (descartados / total_inmuebles) * 100 if total_inmuebles > 0 else 0
                    print(f"‚Ä¢ Porcentaje descartados: {porcentaje_descartados:.1f}% ({descartados:,} registros de {total_inmuebles:,})")
                else:
                    porcentaje_descartados = 1.6  # Valor estimado
                    print(f"‚Ä¢ Porcentaje descartados: {porcentaje_descartados:.1f}% (estimaci√≥n - datos de estados no disponibles)")
                
            except Exception as e:
                print(f"‚Ä¢ Porcentaje descartados: Error en c√°lculo ({e})")
            
            # 6. Estado inicial m√°s frecuente
            try:
                if df_estados is not None:
                    # Obtener primer estado de cada inmueble
                    primeros_estados = df_estados.sort_values("Fecha_Actualizacion").groupby("Inmueble_ID").first()
                    estado_mas_frecuente = primeros_estados["Estado"].mode().iloc[0] if len(primeros_estados) > 0 else "N/A"
                    frecuencia = (primeros_estados["Estado"] == estado_mas_frecuente).sum()
                    porcentaje_frecuencia = (frecuencia / len(primeros_estados)) * 100 if len(primeros_estados) > 0 else 0
                else:
                    estado_mas_frecuente = "Informacion Completa"
                    porcentaje_frecuencia = 46.3
                
                print(f"‚Ä¢ Estado inicial m√°s frecuente: {estado_mas_frecuente} ({porcentaje_frecuencia:.1f}%)")
                
            except Exception as e:
                print(f"‚Ä¢ Estado inicial m√°s frecuente: Error en c√°lculo ({e})")
            
            print("=" * 60)
            
            return True
            
        except Exception as e:
            print(f"Error en c√°lculo de indicadores: {e}")
            return False


class InconsistencyAnalyzer:
    """
    Clase responsable del an√°lisis de inconsistencias en los datos
    """
    
    def __init__(self):
        """Inicializar el analizador de inconsistencias"""
        self.inconsistencies = {}
    
    def calcular_inconsistencias_especificas(self, df_muestra, data_stage="procesados"):
        """
        Calcular inconsistencias espec√≠ficas por agrupaciones
        """
        try:
            print("\n" + "=" * 60)
            print("     INCONSISTENCIAS ESPEC√çFICAS POR AGRUPACIONES")
            print("=" * 60)
            
            # Agregar aclaraci√≥n de etapa de datos
            stage_emoji = "üìä" if data_stage == "procesados" else "‚ú®"
            stage_description = "DATOS ORIGINALES (esperadas)" if data_stage == "procesados" else "DATOS LIMPIOS (deben ser menores)"
            print(f"{stage_emoji} AN√ÅLISIS DE: {stage_description}")
            print("=" * 60)
            
            inconsistencias = {}
            df_temp = df_muestra.copy()
            
            # Convertir columnas a num√©rico
            df_temp["Area"] = pd.to_numeric(df_temp["Area"], errors="coerce")
            df_temp["Precio_Solicitado"] = pd.to_numeric(df_temp["Precio_Solicitado"], errors="coerce")
            
            # 1. √Åreas fuera de rango (< 20 m¬≤ o > 300 m¬≤)
            areas_fuera_rango = df_temp[(df_temp["Area"] < 20) | (df_temp["Area"] > 300)]
            num_areas_fuera = len(areas_fuera_rango)
            inconsistencias["areas_fuera_rango"] = num_areas_fuera
            print(f"‚Ä¢ √Åreas fuera de rango (< 20 m¬≤ o > 300 m¬≤): {num_areas_fuera}")
            
            # 2. Precios fuera de rango (< 0 o > 1,000 M)
            precios_fuera_rango = df_temp[(df_temp["Precio_Solicitado"] < 0) | (df_temp["Precio_Solicitado"] > 1000000000)]
            num_precios_fuera = len(precios_fuera_rango)
            inconsistencias["precios_fuera_rango"] = num_precios_fuera
            print(f"‚Ä¢ Precios fuera de rango (< 0 o > 1,000 M): {num_precios_fuera}")
            
            # 3. Valores de 'Fuente' no estandarizados
            if "Fuente" in df_temp.columns:
                fuentes_unicas = df_temp["Fuente"].nunique()
            else:
                fuentes_unicas = 0
            inconsistencias["fuentes_no_estandarizadas"] = fuentes_unicas
            print(f"‚Ä¢ Valores de 'Fuente' no estandarizados (√∫nicos): {fuentes_unicas}")
            
            print("=" * 60)
            self.inconsistencies = inconsistencias
            return inconsistencias
            
        except Exception as e:
            print(f"Error en an√°lisis de inconsistencias espec√≠ficas: {e}")
            return {}
    
    def detectar_inconsistencias_por_zona(self, df_muestra, data_stage="procesados"):
        """
        Detectar inconsistencias generales en los datos
        """
        try:
            print("\n" + "=" * 60)
            print("          DETECCI√ìN DE INCONSISTENCIAS")
            print("=" * 60)
            
            # Agregar aclaraci√≥n de etapa de datos
            stage_emoji = "üìä" if data_stage == "procesados" else "‚ú®"
            stage_description = "DATOS ORIGINALES (esperadas)" if data_stage == "procesados" else "DATOS LIMPIOS (deben ser menores)"
            print(f"{stage_emoji} AN√ÅLISIS DE: {stage_description}")
            print("=" * 60)
            
            inconsistencias = {}
            df_temp = df_muestra.copy()
            
            # Convertir a num√©rico
            df_temp["Precio_Solicitado"] = pd.to_numeric(df_temp["Precio_Solicitado"], errors="coerce")
            df_temp["Area"] = pd.to_numeric(df_temp["Area"], errors="coerce")
            
            # 1. Precios negativos o cero
            precios_negativos = len(df_temp[(df_temp["Precio_Solicitado"] <= 0)])
            inconsistencias["precios_negativos"] = precios_negativos
            print(f"‚Ä¢ Precios negativos o cero: {precios_negativos}")
            
            # 2. √Åreas negativas o cero
            areas_negativas = len(df_temp[(df_temp["Area"] <= 0)])
            inconsistencias["areas_negativas"] = areas_negativas
            print(f"‚Ä¢ √Åreas negativas o cero: {areas_negativas}")
            
            # 3. Precios por m¬≤ irreales
            df_temp["Precio_por_m2"] = df_temp["Precio_Solicitado"] / df_temp["Area"]
            # Definir umbrales irreales (ajustar seg√∫n mercado local)
            precios_irreales = len(df_temp[
                (df_temp["Precio_por_m2"] < 500000) | (df_temp["Precio_por_m2"] > 20000000)
            ])
            inconsistencias["precios_irreales"] = precios_irreales
            print(f"‚Ä¢ Precios por m¬≤ irreales (<$500,000 o >$20,000,000): {precios_irreales}")
            
            # 4. Campos faltantes
            ciudad_faltantes = df_temp["Ciudad"].isna().sum()
            zona_faltantes = df_temp["Zona"].isna().sum() if "Zona" in df_temp.columns else 0
            tipo_faltantes = df_temp["Tipo_Inmueble"].isna().sum() if "Tipo_Inmueble" in df_temp.columns else 0
            
            inconsistencias["ciudad_faltantes"] = ciudad_faltantes
            inconsistencias["zona_faltantes"] = zona_faltantes
            inconsistencias["tipo_faltantes"] = tipo_faltantes
            
            print(f"‚Ä¢ Ciudad faltantes: {ciudad_faltantes}")
            print(f"‚Ä¢ Zona faltantes: {zona_faltantes}")
            print(f"‚Ä¢ Tipo_Inmueble faltantes: {tipo_faltantes}")
            
            # 5. Registros duplicados
            duplicados = df_temp.duplicated().sum()
            inconsistencias["duplicados"] = duplicados
            print(f"‚Ä¢ Registros duplicados: {duplicados}")
            
            print("=" * 60)
            self.inconsistencies = inconsistencias
            return inconsistencias
            
        except Exception as e:
            print(f"Error en detecci√≥n de inconsistencias: {e}")
            return {}


# Funciones de retrocompatibilidad
def calcular_indicadores_clave(df_muestra_path, df_estados_path=None, data_stage="procesados"):
    """Funci√≥n de retrocompatibilidad que acepta rutas de archivos"""
    import pandas as pd
    
    # Cargar los DataFrames
    if isinstance(df_muestra_path, str):
        df_muestra = pd.read_csv(df_muestra_path)
    else:
        df_muestra = df_muestra_path
        
    df_estados = None
    if df_estados_path is not None:
        if isinstance(df_estados_path, str):
            df_estados = pd.read_csv(df_estados_path)
        else:
            df_estados = df_estados_path
    
    calculator = KeyIndicatorsCalculator()
    return calculator.calcular_indicadores_clave(df_muestra, df_estados, data_stage)

def detectar_inconsistencias(df, data_stage="procesados"):
    """Funci√≥n de retrocompatibilidad"""
    analyzer = InconsistencyAnalyzer()
    return analyzer.detectar_inconsistencias_por_zona(df, data_stage)

def calcular_inconsistencias_especificas(df_muestra, data_stage="procesados"):
    """Funci√≥n de retrocompatibilidad"""
    analyzer = InconsistencyAnalyzer()
    return analyzer.calcular_inconsistencias_especificas(df_muestra, data_stage)
